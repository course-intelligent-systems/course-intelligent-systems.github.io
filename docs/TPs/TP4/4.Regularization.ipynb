{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization: application with medical microbiology diagnosis\n",
    "\n",
    "We want to predict the IBD (Inflammatory Bowel Disease) clinical status of patients **given the abundance of microbial species** living in their gut.\n",
    "\n",
    "Each patient is assigned to a clinical status, and the abundances of known species in their gut are reported in a matrix of size `patient x species`.\n",
    "\n",
    "We focus here on the seminal metagenomic study by Nielsen H.B. et al, published in 2014.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Viz\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "ab_data_pd = pd.read_csv(\"gut_abundances.tsv\", sep=\"\\t\", header = 0)\n",
    "descriptor_names = ab_data_pd.columns\n",
    "ab_data = ab_data_pd.to_numpy()\n",
    "status_txt =  pd.read_csv(\"ibd_status.lst\", sep=\"\\t\", header = None).to_numpy()\n",
    "ab_data_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the data: number of samples ($n$), number of descriptors ($p$), names of descriptors (in ```descriptor_names```), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,p =#TO COMPLETE (1 expression)\n",
    "print(\"Data shape:\",n,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now transform the target variable to a binary (0 ==  control, 1 == IBD) variable ```status```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = np.ravel([int(s == \"IBD\") for s in status_txt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the name of the most correlated species (we denote by S) to the clinical status? Use the ```np.corrcoef``` function to compute the correlation between the data and the status.\n",
    "You can compute the correlation between the data and the status using ```corr_vector = np.corrcoef(ab_data.transpose(),status))[:-1,p]```, which gives the correlation for each species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
 "#TO COMPLETE\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a (naÃ¯ve) predictor that takes as input the abundance of S and output the clinical status of the patient. Either compute the prediction accuracy or its AUC ROC for every threshold, this will be our baseline predictor to improve on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 50% train and 50% test subsets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    ab_data, status, test_size=0.2, shuffle=True\n",
    ")\n",
    "print(x_train.shape)\n",
    "print(ab_data.shape)\n",
    "\n",
    "# We remove species not abundant in the train set\n",
    "col_to_rm = np.where(np.sum(x_train,axis=0) == 0)\n",
    "x_train = np.delete(x_train,col_to_rm,axis=1)\n",
    "x_test =  np.delete(x_test,col_to_rm,axis=1)\n",
    "n,p = x_train.shape\n",
    "\n",
    "# Index of the best correlated species to patient's status\n",
    "best_cor_sp =#TO COMPLETE (1 expression)\n",
    "print(best_cor_sp)\n",
    "\n",
    "# Compute accuracy \n",
    "accuracy = list()\n",
    "ths = np.linspace(0,int(np.max(x_train[:,best_cor_sp]))+1,1000) # threshold list\n",
    "for t in ths:\n",
    "    predictions = (x_train[:,best_cor_sp]>t)\n",
    "    accuracy += [sum( predictions ==#TO COMPLETE (1 expression)\n",
    "\n",
    "    \n",
    "# Plot the decision threshold vs. performance of the predictor\n",
    "\n",
    "plt.scatter(ths,accuracy)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# \"Real\" accuracy on test set\n",
    "# Decision threshold corresponding to the best accuracy.\n",
    "best_ths =#TO COMPLETE (1 expression)\n",
    "# Report the accuracy on the test set\n",
 "#TO COMPLETE\n",
 "#TO COMPLETE\n",
    "\n",
    "\n",
    "roc = roc_auc_score(y_test==1,#TO COMPLETE (1 expression)\n",
    "print(\"AUC ROC on test set:\",roc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we hope that we can do better when using more than 1 descriptor.\n",
    "\n",
    "We will first use a standard [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Use the [`cross_validate`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html ) function of Sklearn to evaluate your predictor in a cross-validation way.\n",
    "\n",
    "Take a look at what metrics you can find in the attributes of the cross-validation object `cv` and print the average accuracy.\n",
    "\n",
    "Do you gain in terms of accuracy compared to a single predictor? Check if you are overfitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = linear_model.LogisticRegression(solver=\"liblinear\")\n",
    "cv =#TO COMPLETE (1 expression)\n",
    "\n",
    "\n",
    "test_score =#TO COMPLETE (1 expression)\n",
    "print(\"Average Cross-Validation accuracy on test:\",test_score)\n",
    "\n",
    "\n",
    "# Split data into 50% train and 50% test subsets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    ab_data, status, test_size=0.5, shuffle=True\n",
    ")\n",
    "\n",
    "# Print example accuracy on 1 fold\n",
 "#TO COMPLETE\n",
 "#TO COMPLETE\n",
 "#TO COMPLETE\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the `coef_` attribute of your model. How many species are you using for taking the decision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_descriptors =#TO COMPLETE (1 expression)\n",
    "print(\"The model uses \",used_descriptors,\"descriptors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering that only few bacterial species may be responsible for IBD, choose a relevant regularization (see the available penalties for logistic regression [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 50% train and 50% test subsets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    ab_data, status, test_size=0.5, shuffle=True\n",
    ")\n",
    "\n",
    "# Create a regularized model\n",
    "logreg_regul =#TO COMPLETE (1 expression)\n",
    "logreg_regul.fit(x_train,y_train)\n",
    "pred = logreg_regul.predict(x_test)\n",
    "\n",
    "# Report accuracy on test set\n",
 "#TO COMPLETE\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you increased the accuracy? Looking at `logreg_regul.coef_`, how many descriptors are you using after regularization?\n",
    "All things considered, is it a better model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_descriptors =#TO COMPLETE (1 expression)\n",
    "print(\"We use \",used_descriptors,\"descriptors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that equivalent accuracy, but with fewer descriptors => more robust and explainable => better model !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the optimal regularization strength, by comparing performances on test set and train set. If you have more time, best is to do it by plotting the mean performance in cross-validation, with confidence enveloppe (+/- std deviation) over the folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 50% train and 50% test subsets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    ab_data, status, test_size=0.5, shuffle=True\n",
    ")\n",
    "\n",
    "acc_test = list()\n",
    "acc_train = list()\n",
    "\n",
    "\n",
    "reg_strengths = [0.001,0.005,0.01,0.03,0.06,0.1,0.15,0.2,0.3,1]\n",
    "for c in reg_strengths:\n",
    "    logreg = linear_model.LogisticRegression(#TO COMPLETE (1 expression)\n",
    "    cv =#TO COMPLETE (1 expression)\n",
    "    acc_test +=#TO COMPLETE (1 expression)\n",
    "    acc_train +=#TO COMPLETE (1 expression)\n",
    "    \n",
    "plt.clf()\n",
    "plt.scatter(reg_strengths,acc_test, label='acc test')\n",
    "plt.scatter(reg_strengths,acc_train, label='acc train')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a classifier on the full dataset with the optimial regularization strength, and interpret the coefficients. You can check in particular if it is consistent with [this paper](https://pubmed.ncbi.nlm.nih.gov/27999802/) and [this one](https://pubmed.ncbi.nlm.nih.gov/20648002/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c is the optimal penalty given the previous graph (hard-code this number)\n",
    "c =#TO COMPLETE (1 expression)\n",
    "logreg = linear_model.LogisticRegression(#TO COMPLETE (1 expression)\n",
    "logreg.fit(ab_data,status)\n",
    "\n",
    "# positive association IBD, you can make use of numpy argsort function\n",
    "order =#TO COMPLETE (1 expression)\n",
    "order = order.tolist()\n",
    "print(np.array(descriptor_names)[order[0][0:3]])\n",
    "\n",
    "\n",
    "# negative association with IBD\n",
    "order =#TO COMPLETE (1 expression)\n",
    "print(np.array(descriptor_names)[order[0][0:3]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: other classifiers\n",
    "\n",
    "Use other models for supervised classification (decision trees, SVM, neural nets, etc.) with the IBD data. Evaluate properly the performances, and pay attention to regularization!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
